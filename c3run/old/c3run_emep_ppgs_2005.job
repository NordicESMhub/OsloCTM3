#!/bin/bash
# Script for running on Abel.
# --------------------------------------------------------------------------
# Job name:
#SBATCH --job-name=C3RUN_emep_ppgs_2005
#
# Project:
#SBATCH --account=nn2806k
#
# Wall clock limit:
#SBATCH --time=150:0:0
#
# Does your job exceed one week, use "--partition=long":
# ####SBATCH --partition=long
#
# Max memory usage:
#SBATCH --mem-per-cpu=3000M
#
# Number of cores:
#SBATCH --ntasks-per-node=16
#
# Number of nodes:
#SBATCH --nodes=1
#
#
## Set up job environment
source /cluster/bin/jobsetup
# --------------------------------------------------------------------------
# No need to change this section

# Must set large stack size (unlimited for simplicity)
ulimit -s unlimited
# Set ulimit also to unlimited (probably not necessary)
ulimit unlimited
# Print out information about ulimit
ulimit -a

# allocate specified memory to each thread (100M)
export THREAD_STACKSIZE=300m
#   ifort uses KMP_STACKSIZE
export KMP_STACKSIZE=$THREAD_STACKSIZE

# number of OpenMP threads - i.e. number of CPUs requested
export OMP_NUM_THREADS=$SLURM_NTASKS_PER_NODE

# the PID number is first the date then an uniqe shell pid
export PID=`date +"%d%m%y".$$`



# Model input data
export INPUT_DATA=$INPUT_OCTM3

# --------------------------------------------------------------------------
# Do changes here

# Model dir - enter your directory here
export MODELDIR=$CTM3_DIR

# Scenario name (use job name or whatever you like)
export SCEN=$SLURM_JOB_NAME

# Scratch directory
export SCRATCH=$WORK/$SCEN

# Result directory (where your files end up)
export RESULTDIR=$WORK/$SCEN.$PID

# Directory for restart
export RESTARTDIR=$RESULTDIR/restart_$PID

# Set input file name
export INPUTFILE=emep_ppgs.inp

# Name of main program
export PROGFILE=osloctm3

# Job file (this file)
export JOBFILE=c3run_emep_ppgs_2005.job

# The dust file
export DUSTFILE=OSLO/DEAD_COLUMN/dustinput/dst_T159.nc

# A restart file
export RESTARTFILE=/usit/abel/u1/sfalk/bin/restart.sav

# Make the scratch directory
if [ ! -d $SCRATCH ]; then mkdir $SCRATCH; fi 

# Put svn info to slurm out
cd $MODELDIR
echo `svn info`
# Go to work directory
cd $SCRATCH

# Restart file is set below
# ...Move the program and the belonging files to $SCRATCH
cp $MODELDIR/$PROGFILE         $SCRATCH/osloctm3
cp $MODELDIR/$INPUTFILE        $SCRATCH/
cp -r $MODELDIR/tables         $SCRATCH/
ln -fs $INPUT_DATA             $SCRATCH/
cp $MODELDIR/$DUSTFILE         $SCRATCH/ 
#   CTM3 restart:  Has to be set accordingly ctm3_restartfile.sav
cp $RESTARTFILE                $SCRATCH/restart.sav #
#cp $RESTARTFILE                $SCRATCH/restart.nc
# if e90-tracer is used, may need restart file
cp $INPUT_DATA/restart_e90.sav $SCRATCH/
# Copy the executing job file to $SCRATCH
cp $0                          $SCRATCH/$JOBFILE




# Run command
./osloctm3 < $INPUTFILE > results.$PID


## Make the result directory
if [ ! -d $RESULTDIR ]; then mkdir $RESULTDIR; fi
echo 'Program completed, copy to '$RESULTDIR
# Copy files to result directory
mv results.$PID     $RESULTDIR/
mv avgsav*          $RESULTDIR/
# Copy the results
mkdir $RESULTDIR/'scavenging_daily'
mv scavenging_daily*.nc            $RESULTDIR/'scavenging_daily'
mkdir $RESULTDIR/'emis'
mv emis*.nc                        $RESULTDIR/'emis'
mv ctm3sltbudget.nc $RESULTDIR/
mv dobson_nmet.nc   $RESULTDIR/
mv ste*.nc          $RESULTDIR/
mv *dta             $RESULTDIR/
mv *.dat            $RESULTDIR/
echo 'Results copied to '$RESULTDIR
mv OSLO/Ltracer*    $RESULTDIR/
#mv *.out            $RESULTDIR/
# Copy restart file
mkdir $RESTARTDIR
mv *restart*.nc     $RESTARTDIR/
mv osloctm3         $RESTARTDIR/
mv *.job            $RESTARTDIR/
mv *.inp            $RESTARTDIR/
mv *.sav            $RESTARTDIR/
mv dst_*.nc         $RESTARTDIR/
cp -r tables        $RESTARTDIR/
echo 'Results copied to '$RESTARTDIR
# Move remaining .nc files
mv *.nc             $RESULTDIR/

# Done
# --------------------------------------------------------------------------

